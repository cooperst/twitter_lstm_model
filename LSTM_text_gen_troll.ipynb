{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f1a77fb-4b5b-407a-aad8-b5a5ef2dd4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import string\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47784541-c0a9-4766-84a9-674dd6d95764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "url_pat = re.compile(r'(http\\S+|www\\.\\S+)', flags=re.IGNORECASE)\n",
    "num_pat = re.compile(r'\\d+')\n",
    "\n",
    "def remove_urls_nums(text):\n",
    "    text = num_pat.sub('', text)       # remove numbers\n",
    "    text = url_pat.sub('', text)       # remove URLs\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text) # remove all non-alphabet or numeric values\n",
    "    return text.strip()                        # some data had numbers attatched to letters and num_pat couldn't remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54f555f8-a730-4b30-99fe-9ded00f14de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def split_file(input, output, max_size = 6 * 1024**2):\n",
    "    os.makedirs(output, exist_ok=True)\n",
    "    base = os.path.basename(input)\n",
    "    part = 0\n",
    "    current_size = 0\n",
    "    out = None\n",
    "\n",
    "    with open(input, \"rb\") as f:\n",
    "        for line in f:\n",
    "            if out is None or current_size + len(line) > max_size:\n",
    "                if out:\n",
    "                    out.close()\n",
    "                part += 1\n",
    "                out_path = os.path.join(output, f\"chunk.part{part:d}.txt\")\n",
    "                out = open(out_path, \"wb\")\n",
    "                current_size = 0\n",
    "            out.write(line)\n",
    "            current_size += len(line)\n",
    "    if out:\n",
    "        print(f\"Split {input} into {part} parts\")\n",
    "        out.close()\n",
    "    return part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b38e905-1c97-4e5d-9d5c-21f8cfdfb58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split combined_troll.txt into 49 parts\n"
     ]
    }
   ],
   "source": [
    "split_troll = split_file(\"combined_troll.txt\", \"chunks\", max_size = 6 * 1024**2 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1321ca75-4d8b-4feb-af58-b4a8a9539800",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_pat = re.compile(r'http\\S+', flags = re.IGNORECASE)\n",
    "\n",
    "with open(\"chunk.part20.txt\", \"r\", encoding = \"utf-8\") as t:\n",
    "    text = t.read()\n",
    "    \n",
    "data = text.splitlines()\n",
    "data = [remove_urls_nums(line) for line in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911137dd",
   "metadata": {},
   "source": [
    "#### LSTM model and train test preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1babd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(data) #it's going to fit on the data in the forms of lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de90b86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text=tokenizer.texts_to_sequences(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63af34c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(tokenizer.word_counts)+1 # always add plus one in tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33262d23",
   "metadata": {},
   "source": [
    "### Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c32ae96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list=[]\n",
    "for i in encoded_text:\n",
    "    if len(i)>1:\n",
    "        for j in range(2,len(i)+1):\n",
    "            data_list.append(i[:j])\n",
    "# put each word in the array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f592d01d",
   "metadata": {},
   "source": [
    "#### Paddding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "905f8572",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=40\n",
    "#max length of line is 40 tokens per line in each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a7c4079",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences=pad_sequences(data_list,maxlen=max_length,padding=\"pre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f1a3a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=sequences[:,:-1]\n",
    "y=sequences[:,-1].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c56f1861-0cea-404e-999f-441c04d716fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((452326, 39), (452326,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd466740",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length=X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e6e819",
   "metadata": {},
   "source": [
    "#### Build Model\n",
    "- We will build a simple LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb22d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size,50)) \n",
    "model.add(LSTM(100,return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100,activation=\"relu\"))\n",
    "model.add(Dense(vocab_size,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5665f431-1b98-4352-ae71-317090aef27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape=(None, seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d6f5963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)             </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">   Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">8,570,350</span> │\n",
       "├──────────────────────────┼───────────────────┼───────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">60,400</span> │\n",
       "├──────────────────────────┼───────────────────┼───────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │\n",
       "├──────────────────────────┼───────────────────┼───────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├──────────────────────────┼───────────────────┼───────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">171407</span>)    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">17,312,1…</span> │\n",
       "└──────────────────────────┴───────────────────┴───────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m50\u001b[0m)    │ \u001b[38;5;34m8,570,350\u001b[0m │\n",
       "├──────────────────────────┼───────────────────┼───────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m100\u001b[0m)   │    \u001b[38;5;34m60,400\u001b[0m │\n",
       "├──────────────────────────┼───────────────────┼───────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │    \u001b[38;5;34m80,400\u001b[0m │\n",
       "├──────────────────────────┼───────────────────┼───────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │    \u001b[38;5;34m10,100\u001b[0m │\n",
       "├──────────────────────────┼───────────────────┼───────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m171407\u001b[0m)    │ \u001b[38;5;34m17,312,1…\u001b[0m │\n",
       "└──────────────────────────┴───────────────────┴───────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,033,357</span> (99.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,033,357\u001b[0m (99.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,033,357</span> (99.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,033,357\u001b[0m (99.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62c42ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f06cbeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m698s\u001b[0m 395ms/step - accuracy: 0.0234 - loss: 9.5607\n",
      "Epoch 2/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m713s\u001b[0m 404ms/step - accuracy: 0.0405 - loss: 8.9632\n",
      "Epoch 3/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m722s\u001b[0m 408ms/step - accuracy: 0.0519 - loss: 8.5205\n",
      "Epoch 4/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m721s\u001b[0m 408ms/step - accuracy: 0.0583 - loss: 8.1945\n",
      "Epoch 5/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m723s\u001b[0m 409ms/step - accuracy: 0.0627 - loss: 7.9082\n",
      "Epoch 6/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m736s\u001b[0m 417ms/step - accuracy: 0.0670 - loss: 7.6299\n",
      "Epoch 7/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m749s\u001b[0m 424ms/step - accuracy: 0.0710 - loss: 7.3398\n",
      "Epoch 8/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m737s\u001b[0m 417ms/step - accuracy: 0.0753 - loss: 7.0270\n",
      "Epoch 9/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m722s\u001b[0m 409ms/step - accuracy: 0.0801 - loss: 6.6903\n",
      "Epoch 10/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m722s\u001b[0m 408ms/step - accuracy: 0.0857 - loss: 6.3109\n",
      "Epoch 11/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m750s\u001b[0m 424ms/step - accuracy: 0.0935 - loss: 5.9221\n",
      "Epoch 12/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m741s\u001b[0m 419ms/step - accuracy: 0.1070 - loss: 5.5535\n",
      "Epoch 13/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m750s\u001b[0m 424ms/step - accuracy: 0.1261 - loss: 5.2228\n",
      "Epoch 14/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m743s\u001b[0m 420ms/step - accuracy: 0.1525 - loss: 4.9191\n",
      "Epoch 15/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m756s\u001b[0m 428ms/step - accuracy: 0.1833 - loss: 4.6475\n",
      "Epoch 16/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m748s\u001b[0m 423ms/step - accuracy: 0.2168 - loss: 4.3978\n",
      "Epoch 17/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m732s\u001b[0m 415ms/step - accuracy: 0.2511 - loss: 4.1724\n",
      "Epoch 18/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m729s\u001b[0m 413ms/step - accuracy: 0.2858 - loss: 3.9695\n",
      "Epoch 19/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m722s\u001b[0m 409ms/step - accuracy: 0.3168 - loss: 3.7878\n",
      "Epoch 20/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m725s\u001b[0m 410ms/step - accuracy: 0.3456 - loss: 3.6220\n",
      "Epoch 21/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m744s\u001b[0m 421ms/step - accuracy: 0.3712 - loss: 3.4754\n",
      "Epoch 22/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m742s\u001b[0m 420ms/step - accuracy: 0.3946 - loss: 3.3447\n",
      "Epoch 23/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m722s\u001b[0m 408ms/step - accuracy: 0.4144 - loss: 3.2299\n",
      "Epoch 24/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m718s\u001b[0m 406ms/step - accuracy: 0.4320 - loss: 3.1296\n",
      "Epoch 25/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m721s\u001b[0m 408ms/step - accuracy: 0.4468 - loss: 3.0410\n",
      "Epoch 26/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m731s\u001b[0m 414ms/step - accuracy: 0.4602 - loss: 2.9599\n",
      "Epoch 27/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m742s\u001b[0m 420ms/step - accuracy: 0.4729 - loss: 2.8876\n",
      "Epoch 28/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2771s\u001b[0m 2s/step - accuracy: 0.4834 - loss: 2.8224\n",
      "Epoch 29/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2000s\u001b[0m 1s/step - accuracy: 0.4932 - loss: 2.7625\n",
      "Epoch 30/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m717s\u001b[0m 406ms/step - accuracy: 0.5022 - loss: 2.7087\n",
      "Epoch 31/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m724s\u001b[0m 410ms/step - accuracy: 0.5094 - loss: 2.6613\n",
      "Epoch 32/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m724s\u001b[0m 410ms/step - accuracy: 0.5176 - loss: 2.6112\n",
      "Epoch 33/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m735s\u001b[0m 416ms/step - accuracy: 0.5237 - loss: 2.5711\n",
      "Epoch 34/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m740s\u001b[0m 419ms/step - accuracy: 0.5298 - loss: 2.5305\n",
      "Epoch 35/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m747s\u001b[0m 423ms/step - accuracy: 0.5357 - loss: 2.4931\n",
      "Epoch 36/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m753s\u001b[0m 426ms/step - accuracy: 0.5410 - loss: 2.4572\n",
      "Epoch 37/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m754s\u001b[0m 427ms/step - accuracy: 0.5458 - loss: 2.4221\n",
      "Epoch 38/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m754s\u001b[0m 427ms/step - accuracy: 0.5505 - loss: 2.3921\n",
      "Epoch 39/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m748s\u001b[0m 423ms/step - accuracy: 0.5546 - loss: 2.3599\n",
      "Epoch 40/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m744s\u001b[0m 421ms/step - accuracy: 0.5585 - loss: 2.3328\n",
      "Epoch 41/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5714s\u001b[0m 3s/step - accuracy: 0.5630 - loss: 2.3055\n",
      "Epoch 42/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m530s\u001b[0m 300ms/step - accuracy: 0.5668 - loss: 2.2781\n",
      "Epoch 43/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m532s\u001b[0m 301ms/step - accuracy: 0.5712 - loss: 2.2507\n",
      "Epoch 44/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m521s\u001b[0m 295ms/step - accuracy: 0.5737 - loss: 2.2275\n",
      "Epoch 45/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m518s\u001b[0m 293ms/step - accuracy: 0.5770 - loss: 2.2039\n",
      "Epoch 46/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m520s\u001b[0m 294ms/step - accuracy: 0.5811 - loss: 2.1785\n",
      "Epoch 47/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 290ms/step - accuracy: 0.5835 - loss: 2.1582\n",
      "Epoch 48/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m515s\u001b[0m 291ms/step - accuracy: 0.5868 - loss: 2.1392\n",
      "Epoch 49/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 291ms/step - accuracy: 0.5902 - loss: 2.1172\n",
      "Epoch 50/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 290ms/step - accuracy: 0.5923 - loss: 2.0995\n",
      "Epoch 51/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 290ms/step - accuracy: 0.5952 - loss: 2.0787\n",
      "Epoch 52/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m519s\u001b[0m 294ms/step - accuracy: 0.5980 - loss: 2.0620\n",
      "Epoch 53/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m527s\u001b[0m 298ms/step - accuracy: 0.6005 - loss: 2.0433\n",
      "Epoch 54/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 299ms/step - accuracy: 0.6024 - loss: 2.0266\n",
      "Epoch 55/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 296ms/step - accuracy: 0.6051 - loss: 2.0107\n",
      "Epoch 56/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m521s\u001b[0m 295ms/step - accuracy: 0.6078 - loss: 1.9938\n",
      "Epoch 57/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m518s\u001b[0m 293ms/step - accuracy: 0.6096 - loss: 1.9806\n",
      "Epoch 58/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m511s\u001b[0m 289ms/step - accuracy: 0.6125 - loss: 1.9640\n",
      "Epoch 59/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m510s\u001b[0m 289ms/step - accuracy: 0.6141 - loss: 1.9501\n",
      "Epoch 60/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m512s\u001b[0m 290ms/step - accuracy: 0.6164 - loss: 1.9360\n",
      "Epoch 61/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m518s\u001b[0m 293ms/step - accuracy: 0.6180 - loss: 1.9235\n",
      "Epoch 62/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m527s\u001b[0m 298ms/step - accuracy: 0.6205 - loss: 1.9080\n",
      "Epoch 63/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m523s\u001b[0m 296ms/step - accuracy: 0.6219 - loss: 1.8965\n",
      "Epoch 64/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m519s\u001b[0m 293ms/step - accuracy: 0.6235 - loss: 1.8855\n",
      "Epoch 65/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 291ms/step - accuracy: 0.6260 - loss: 1.8709\n",
      "Epoch 66/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 291ms/step - accuracy: 0.6284 - loss: 1.8596\n",
      "Epoch 67/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 291ms/step - accuracy: 0.6294 - loss: 1.8479\n",
      "Epoch 68/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 291ms/step - accuracy: 0.6308 - loss: 1.8370\n",
      "Epoch 69/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m518s\u001b[0m 293ms/step - accuracy: 0.6324 - loss: 1.8258\n",
      "Epoch 70/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m527s\u001b[0m 298ms/step - accuracy: 0.6344 - loss: 1.8140\n",
      "Epoch 71/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m531s\u001b[0m 300ms/step - accuracy: 0.6363 - loss: 1.8022\n",
      "Epoch 72/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m527s\u001b[0m 298ms/step - accuracy: 0.6380 - loss: 1.7919\n",
      "Epoch 73/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m522s\u001b[0m 295ms/step - accuracy: 0.6396 - loss: 1.7823\n",
      "Epoch 74/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m531s\u001b[0m 300ms/step - accuracy: 0.6412 - loss: 1.7712\n",
      "Epoch 75/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m520s\u001b[0m 294ms/step - accuracy: 0.6425 - loss: 1.7613\n",
      "Epoch 76/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m522s\u001b[0m 295ms/step - accuracy: 0.6438 - loss: 1.7534\n",
      "Epoch 77/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m529s\u001b[0m 299ms/step - accuracy: 0.6453 - loss: 1.7438\n",
      "Epoch 78/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m515s\u001b[0m 292ms/step - accuracy: 0.6473 - loss: 1.7327\n",
      "Epoch 79/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m533s\u001b[0m 302ms/step - accuracy: 0.6480 - loss: 1.7254\n",
      "Epoch 80/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m539s\u001b[0m 305ms/step - accuracy: 0.6495 - loss: 1.7156\n",
      "Epoch 81/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 299ms/step - accuracy: 0.6510 - loss: 1.7067\n",
      "Epoch 82/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m531s\u001b[0m 300ms/step - accuracy: 0.6522 - loss: 1.6988\n",
      "Epoch 83/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 296ms/step - accuracy: 0.6531 - loss: 1.6897\n",
      "Epoch 84/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m518s\u001b[0m 293ms/step - accuracy: 0.6549 - loss: 1.6819\n",
      "Epoch 85/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 299ms/step - accuracy: 0.6558 - loss: 1.6748\n",
      "Epoch 86/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 292ms/step - accuracy: 0.6546 - loss: 1.6814\n",
      "Epoch 87/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m520s\u001b[0m 294ms/step - accuracy: 0.6592 - loss: 1.6549\n",
      "Epoch 88/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m527s\u001b[0m 298ms/step - accuracy: 0.6597 - loss: 1.6495\n",
      "Epoch 89/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m540s\u001b[0m 306ms/step - accuracy: 0.6608 - loss: 1.6426\n",
      "Epoch 90/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 299ms/step - accuracy: 0.6625 - loss: 1.6355\n",
      "Epoch 91/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 303ms/step - accuracy: 0.6637 - loss: 1.6276\n",
      "Epoch 92/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m523s\u001b[0m 296ms/step - accuracy: 0.6643 - loss: 1.6229\n",
      "Epoch 93/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 297ms/step - accuracy: 0.6657 - loss: 1.6122\n",
      "Epoch 94/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 299ms/step - accuracy: 0.6666 - loss: 1.6081\n",
      "Epoch 95/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m529s\u001b[0m 299ms/step - accuracy: 0.6675 - loss: 1.6010\n",
      "Epoch 96/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m530s\u001b[0m 300ms/step - accuracy: 0.6690 - loss: 1.5927\n",
      "Epoch 97/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m525s\u001b[0m 297ms/step - accuracy: 0.6704 - loss: 1.5848\n",
      "Epoch 98/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m532s\u001b[0m 301ms/step - accuracy: 0.6709 - loss: 1.5804\n",
      "Epoch 99/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 291ms/step - accuracy: 0.6716 - loss: 1.5737\n",
      "Epoch 100/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m529s\u001b[0m 300ms/step - accuracy: 0.6731 - loss: 1.5682\n",
      "Epoch 101/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m515s\u001b[0m 291ms/step - accuracy: 0.6741 - loss: 1.5585\n",
      "Epoch 102/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m529s\u001b[0m 299ms/step - accuracy: 0.6751 - loss: 1.5534\n",
      "Epoch 103/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m533s\u001b[0m 301ms/step - accuracy: 0.6765 - loss: 1.5479\n",
      "Epoch 104/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m539s\u001b[0m 305ms/step - accuracy: 0.6771 - loss: 1.5414\n",
      "Epoch 105/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m613s\u001b[0m 347ms/step - accuracy: 0.6776 - loss: 1.5385\n",
      "Epoch 106/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m547s\u001b[0m 310ms/step - accuracy: 0.6785 - loss: 1.5312\n",
      "Epoch 107/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m535s\u001b[0m 303ms/step - accuracy: 0.6796 - loss: 1.5258\n",
      "Epoch 108/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 307ms/step - accuracy: 0.6800 - loss: 1.5214\n",
      "Epoch 109/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 307ms/step - accuracy: 0.6817 - loss: 1.5153\n",
      "Epoch 110/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m526s\u001b[0m 298ms/step - accuracy: 0.6825 - loss: 1.5086\n",
      "Epoch 111/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 302ms/step - accuracy: 0.6834 - loss: 1.5032\n",
      "Epoch 112/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m533s\u001b[0m 302ms/step - accuracy: 0.6838 - loss: 1.4991\n",
      "Epoch 113/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m525s\u001b[0m 297ms/step - accuracy: 0.6849 - loss: 1.4933\n",
      "Epoch 114/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m535s\u001b[0m 303ms/step - accuracy: 0.6859 - loss: 1.4889\n",
      "Epoch 115/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m549s\u001b[0m 310ms/step - accuracy: 0.6861 - loss: 1.4860\n",
      "Epoch 116/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 311ms/step - accuracy: 0.6876 - loss: 1.4790\n",
      "Epoch 117/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m553s\u001b[0m 313ms/step - accuracy: 0.6880 - loss: 1.4738\n",
      "Epoch 118/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 303ms/step - accuracy: 0.6890 - loss: 1.4707\n",
      "Epoch 119/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 302ms/step - accuracy: 0.6903 - loss: 1.4614\n",
      "Epoch 120/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 303ms/step - accuracy: 0.6905 - loss: 1.4614\n",
      "Epoch 121/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 297ms/step - accuracy: 0.6912 - loss: 1.4566\n",
      "Epoch 122/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 302ms/step - accuracy: 0.6916 - loss: 1.4528\n",
      "Epoch 123/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 297ms/step - accuracy: 0.6928 - loss: 1.4468\n",
      "Epoch 124/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m533s\u001b[0m 302ms/step - accuracy: 0.6939 - loss: 1.4415\n",
      "Epoch 125/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 303ms/step - accuracy: 0.6938 - loss: 1.4398\n",
      "Epoch 126/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m522s\u001b[0m 295ms/step - accuracy: 0.6947 - loss: 1.4362\n",
      "Epoch 127/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m537s\u001b[0m 304ms/step - accuracy: 0.6956 - loss: 1.4302\n",
      "Epoch 128/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m538s\u001b[0m 305ms/step - accuracy: 0.6962 - loss: 1.4260\n",
      "Epoch 129/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m538s\u001b[0m 305ms/step - accuracy: 0.6959 - loss: 1.4258\n",
      "Epoch 130/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m549s\u001b[0m 311ms/step - accuracy: 0.6974 - loss: 1.4188\n",
      "Epoch 131/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m539s\u001b[0m 305ms/step - accuracy: 0.6983 - loss: 1.4145\n",
      "Epoch 132/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m535s\u001b[0m 303ms/step - accuracy: 0.6994 - loss: 1.4098\n",
      "Epoch 133/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m539s\u001b[0m 305ms/step - accuracy: 0.6996 - loss: 1.4078\n",
      "Epoch 134/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 302ms/step - accuracy: 0.6999 - loss: 1.4027\n",
      "Epoch 135/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m539s\u001b[0m 305ms/step - accuracy: 0.7010 - loss: 1.3997\n",
      "Epoch 136/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 307ms/step - accuracy: 0.7010 - loss: 1.3982\n",
      "Epoch 137/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m535s\u001b[0m 303ms/step - accuracy: 0.7019 - loss: 1.3924\n",
      "Epoch 138/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 303ms/step - accuracy: 0.7021 - loss: 1.3887\n",
      "Epoch 139/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m539s\u001b[0m 305ms/step - accuracy: 0.7032 - loss: 1.3851\n",
      "Epoch 140/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m525s\u001b[0m 297ms/step - accuracy: 0.7037 - loss: 1.3807\n",
      "Epoch 141/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 308ms/step - accuracy: 0.7040 - loss: 1.3788\n",
      "Epoch 142/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m585s\u001b[0m 331ms/step - accuracy: 0.7052 - loss: 1.3726\n",
      "Epoch 143/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 318ms/step - accuracy: 0.7057 - loss: 1.3687\n",
      "Epoch 144/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 320ms/step - accuracy: 0.7065 - loss: 1.3672\n",
      "Epoch 145/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m587s\u001b[0m 332ms/step - accuracy: 0.7067 - loss: 1.3638\n",
      "Epoch 146/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m601s\u001b[0m 340ms/step - accuracy: 0.7074 - loss: 1.3583\n",
      "Epoch 147/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m596s\u001b[0m 337ms/step - accuracy: 0.7081 - loss: 1.3567\n",
      "Epoch 148/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m586s\u001b[0m 332ms/step - accuracy: 0.7083 - loss: 1.3537\n",
      "Epoch 149/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m581s\u001b[0m 329ms/step - accuracy: 0.7092 - loss: 1.3497\n",
      "Epoch 150/150\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 327ms/step - accuracy: 0.7100 - loss: 1.3443\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X,y,batch_size=256,epochs=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e41f61",
   "metadata": {},
   "source": [
    "### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56f2d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length = 15\n",
    "\n",
    "def generate_text(input_text, no_lines):\n",
    "    general_text = []\n",
    "    original_input = input_text  # keep the original prefix\n",
    "\n",
    "    for i in range(no_lines):\n",
    "        text = []\n",
    "        for _ in range(text_length):\n",
    "            encoded = tokenizer.texts_to_sequences([input_text])\n",
    "            encoded = pad_sequences(encoded, maxlen=seq_length, padding=\"pre\")\n",
    "            y_pred = np.argmax(model.predict(encoded), axis=-1)\n",
    "\n",
    "            predicted_word = \"\"\n",
    "            for word, index in tokenizer.word_index.items():\n",
    "                if index == y_pred:\n",
    "                    predicted_word = word\n",
    "                    break\n",
    "\n",
    "            input_text = input_text + ' ' + predicted_word\n",
    "            text.append(predicted_word)\n",
    "\n",
    "        line = original_input + \" \" + \" \".join(text)\n",
    "        general_text.append(line)\n",
    "\n",
    "        input_text = text[-1]\n",
    "\n",
    "    return general_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1cf2ba28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['There are no active watches warnings or advisories ohwx wcen reflecting wwe and magpul zero global a',\n",
       " 'There are good workout is the best relief gaboriks kenssnapback talinatalie shanpanda jonathonaalders iamchiefsosa freshaziceblue andrewmajano karkarj',\n",
       " 'There are gotherpeepin nick ovoxojulio taylor megankrings the jennabeadles jo trilljo rob satiuqul su ade yoshie cathleenking']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text=\"There are\"\n",
    "text_produced=generate_text(input_text,3)\n",
    "text_produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "191597eb-292e-448d-988b-ddfe08b7424f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['How do you workout with me lillianolivia imjesssayinx denissemorales gelleesh sheiskandi laurenderise sfgamerbabe avyzmprotect runnarghhh runnarghhh runnarghhh',\n",
       " 'How do woosang knight knightkingbaal earth astraeanixie unthinkable livelaughlynn abbie starr steven wellness hayden billy devin hughes',\n",
       " 'How do knuckles demoalpha sillyman mady madybaker jaylon ayeejaysimp fj medeya bruno vallencourt max jones musgrove raven']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text=\"How do\"\n",
    "text_produced=generate_text(input_text,3)\n",
    "text_produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9249f926-37cc-471b-925f-8381e719ebba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['When will heartcatchr inkscrblr inkscrblr inkscrblr chloeravioli anglebre austinfortner medinax medinax ronsouthwick ronsouthwick ibleedcamo vodkahelps simbra simbra',\n",
       " 'When will metalmoccha heartcatchr inkscrblr inkscrblr inkscrblr inkscrblr inkscrblr ddubsnyrangel ddubsnyrangel medinax medinax joeadamo tharealcorygunz twinrose twinrose',\n",
       " 'When will metalmoccha jeremyjdaguilar jeremyjdaguilar jeremyjdaguilar tim farrizjusoffe trentwilliams synergyblitz inkscrblr synergyblitz ddubsnyrangel ddubsnyrangel selfemploydking synergyblitz misslouisekay']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text=\"When will\"\n",
    "text_produced=generate_text(input_text,3)\n",
    "text_produced"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
