{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f1a77fb-4b5b-407a-aad8-b5a5ef2dd4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import string\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47784541-c0a9-4766-84a9-674dd6d95764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "url_pat = re.compile(r'(http\\S+|www\\.\\S+)', flags=re.IGNORECASE)\n",
    "num_pat = re.compile(r'\\d+')\n",
    "\n",
    "def remove_urls_nums(text):\n",
    "    text = num_pat.sub('', text)       # remove numbers\n",
    "    text = url_pat.sub('', text)       # remove URLs\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text) # remove all non-alphabet or numeric values\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54f555f8-a730-4b30-99fe-9ded00f14de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def split_file(input, output, max_size = 6 * 1024**2):\n",
    "    os.makedirs(output, exist_ok=True)\n",
    "    base = os.path.basename(input)\n",
    "    part = 0\n",
    "    current_size = 0\n",
    "    out = None\n",
    "\n",
    "    with open(input, \"rb\") as f:\n",
    "        for line in f:\n",
    "            if out is None or current_size + len(line) > max_size:\n",
    "                if out:\n",
    "                    out.close()\n",
    "                part += 1\n",
    "                out_path = os.path.join(output, f\"chunk.part{part:d}.txt\")\n",
    "                out = open(out_path, \"wb\")\n",
    "                current_size = 0\n",
    "            out.write(line)\n",
    "            current_size += len(line)\n",
    "    if out:\n",
    "        print(f\"Split {input} into {part} parts\")\n",
    "        out.close()\n",
    "    return part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b38e905-1c97-4e5d-9d5c-21f8cfdfb58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split_troll = split_file(\"combined_gen.txt\", \"chunks_gen\", max_size = 6 * 1024**2 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1321ca75-4d8b-4feb-af58-b4a8a9539800",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"chunk.part19.txt\", \"r\", encoding = \"utf-8\") as t:\n",
    "    text = t.read()\n",
    "    \n",
    "data = text.splitlines()\n",
    "data = [remove_urls_nums(line) for line in data]\n",
    "data = [dt for dt in data if dt.strip() != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a564a3b-e0bc-4b90-91ec-026bfcc7351e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Baltimorebased', 'division', 'of', 'All', 'Inventions', 'of', 'a', 'Generation', 'Think', 'about', 'what', 'you', 'do', 'in', 'the', 'morning', 'every', 'procedure', 'you', 'take', 'part', 'in', 'includes', 'an', 'Larger', 'role', 'for', 'Chinese', 'Indian', 'inventors', 'in', 'US', 'This', 'is', 'brought', 'out', 'in', 'a', 'new', 'study', 'published', 'by', 'the', 'Natio', 'No', 'snow', 'job', 'For', 'serial', 'inventor', 'Arra', 'David', 'the', 'product', 'category', 'was', 'ripe', 'for', 'a', 'makeover', 'He', 'invented', 'the', 'Rebo', 'City', 'firm', 'sues', 'gaming', 'giants', 'Eleven', 'contends', 'the', 'wireless', 'controllers', 'for', 'the', 'Nintendo', 'Wii', 'Sony', 'Playstation', 'Four', 'Shows', 'in', 'the', 'Next', 'Two', 'Weeks', 'Sure', 'I', 'Can', 'Do', 'That', 'Atelier', 'Highlandtown', 'Holiday', 'Craft', 'Show', 'Sunday', 'w', 'WikiAnswers', 'Did', 'the', 'invention', 'of', 'the', 'cell', 'phone', 'inspire', 'other', 'Mobile', 'Phones', 'question', 'Did', 'the', 'invention', 'The', 'Inventions', 'The', 'R', 'by', 'Anh', 'Nguyen', 'I', 'know', 'polluting', 'is', 'a', 'big', 'problem', 'on', 'Earth', 'So', 'I', 'am', 'planning', 'to', 'inven', 'Clickfree', 'Automatic', 'Backup', 'Announces', 'Partnerships', 'with', 'Prominent', 'North', 'As', 'the', 'inventors', 'of', 'effortless', 'cons', 'Tribot', 'How', 'Can', 'You', 'Not', 'Love', 'Him', 'InventorSpot', 'Looking', 'for', 'a', 'great', 'Christmas', 'gift', 'How', 'can', 'you', 'turn', 'down', 'a', 'Other', 'Legal', 'Work', 'Slow', 'Start', 'A', 'Practice', 'To', 'Help', 'Patent', 'Trolling', 'We', 'get', 'people', 'patenting', 'ideas', 'for', 'inventions', 'News', 'From', 'Charm', 'City', 'Craft', 'Mafia', 'Holiday', 'Heap', 'Vendor', 'Maneating', 'A', 'common', 'gripe', 'among', 'my', 'guy', 'friends', 'that', 'IP', 'Alert', 'an', 'iSheets', 'product', 'An', 'invention', 'relating', 'to', 'the', 'presentation', 'of', 'programme', 'information', 'on', 'a', 'TV', 'scre', 'Ian', 'Shires', 'Blog', 'Archive', 'Ornamental', 'Arch', 'at', 'New', 'Inventions', 'Council', 'workmen', 'have', 'today', 'had', 'to', 'remov', 'Big', 'Bang', 'Machine', 'Sets', 'Power', 'Record', 'Inventions', 'Patents', 'New', 'Big', 'Bang', 'Machine', 'Sets', 'Wearable', 'Pet', 'Carrier', 'Actual', 'Inventions', 'Pics', 'Videos', 'Links', 'News', 'Wearable', 'Pet', 'Carrier', 'Actual', 'Inventio', 'Obama', 'to', 'honor', 'young', 'inventors', 'at', 'science', 'fair', 'Obama', 'says', 'White', 'House', 'will', 'host', 'national', 'science', 'fair', 'to', 'honor', 'SWI', 'cities', 'hopping', 'with', 'holiday', 'activities', 'A', 'craft', 'fair', 'will', 'start', 'at', 'pm', 'Santa', 'will', 'be', 'at', 'the', 'fire', 'hall', 'from', 'Laser', 'Blaster', 'at', 'Star', 'City', 'David', 'Small', 'and', 'Paul', 'Rago', 'both', 'inventors', 'for', 'the', 'toy', 'development', 'company', 'Shoot', 'the', 'Free', 'cheap', 'events', 'Arts', 'and', 'crafts', 'show', 'and', 'sale', 'am', 'pm', 'Dec', 'Free', 'Sonoran', 'Desert', 'Wee', 'Craft', 'fair', 'continues', 'today', 'at', 'fairgrounds', 'The', 'annual', 'Christmas', 'Craft', 'Fair', 'opened', 'on', 'Friday', 'and', 'continues', 'from', 'Murdoch', 'and', 'Google', 'chief', 'not', 'all', 'at', 'odds', 'In the future we will provide our content to devices that today', 'Investors inventor left behind in apparent scam  The KeelyNet Blog Scientist and inventor Oskar Klenert spe', 'Handmade Craft Shows  Apartment Therapy ReNest If youre looking to give handmade this season try hi', 'NewProductHelpcom Tabbed as Official Marketing Representative of Hose Tool  Jason B Texasbased inventor', 'The Pretty People Have Arrived in South Beach Jaunted', 'sail on the Island Queen where guides will point ou', 'Outdoor Craft Shows Outdoor craft shows are an excellent place to demonstrate all of your handmade jewelries T', 'Models and Inventions Model training building finishing designing Models and Inventions NITRO PLANES GETT', 'Science Musings Blog For all of the great', 'inventions', 'on', 'Lanes', 'list', 'we', 'are', 'a', 'long', 'way', 'from', 'ex', 'Local', 'artisans', 'display', 'wares', 'at', 'show', 'Above', 'Sonja', 'Vanderberry', 'shops', 'at', 'the', 'Society', 'of', 'Arts', 'and', 'Crafts', 't', 'Inventions', 'for', 'the', 'world', 'Mreloy', 'Learn', 'English', 'at', 'EnglishCafe', 'What', 'were', 'you', 'favorite', 'inventions', 'which', 'm', 'Invention', 'Livesciencecom', 'Find', 'out', 'everything', 'there', 'is', 'to', 'know', 'about', 'inventions', 'and', 'stay', 'updated', 'on', 'the', 'late', 'Daly', 'Mansion', 'made', 'for', 'Yuletide', 'decor', 'We got done with our Holly Jolly Craft Show and after that the gi', 'Women Inventors  Cuba MrsRM Ms Ferreiro is the main inventor titular researcher and Deputy Director of t', 'Inventors to be topic of Rev King essay contest  The Sun  Throughout history AfricanAmericans have inve', 'DECK THE HALLS Pueblo Chieftain They promote new items', 'said', 'Ball', 'who', 'built', 'up', 'her', 'charm', 'sales', 'business', 'Art', 'Shows', 'that', 'serve', 'the', 'holiday', 'mood', 'Philadelphia', 'Inquirer', 'His', 'comical', 'inventions', 'from', 'the', 'b', 'Best', 'Netbook', 'Deals', 'The', 'New', 'Invention', 'in', 'This', 'Creative', 'World', 'You', 'can', 'discover', 'new', 'places', 'and', 'new', 'inventions', 'T', 'Events', 'Christmas', 'craft', 'show', 'and', 'bake', 'sale', 'Chillicothe', 'OH', 'Chillicothe', 'OH', 'News', 'chillicothegazet', 'Nashville', 'students', 'win', 'for', 'inventions', 'Metro', 'Nashville', 'Public', 'Schools', 'Invention', 'Convention', 'winners', 'were', 'an', 'GLOBAL', 'Copenhagen', 'dispute', 'over', 'IP', 'Proposals', 'from', 'China', 'and', 'India', 'for', 'the', 'Copenhagen', 'climate', 'change', 'conference', 'People', 'want', 'more', 'of', 'Blanches', 'fruitcake', 'She', 'attended', 'art', 'and', 'craft', 'shows', 'to', 'introduce', 'the', 'cakes', 'and', 'starte', 'Lenape', 'student', 'scientists', 'take', 'center', 'stage', 'On', 'Saturday', 'a', 'crowd', 'of', 'more', 'than', 'people', 'at', 'Burlington', 'County', 'Young', 'inventors', 'show', 'creativity', 'Those', 'were', 'among', 'the', 'student', 'inventions', 'featured', 'at', 'the', 'Gulfside', 'Elementary', 'A', 'Look', 'Back', 'Gadget', 'inventors', 'wife', 'put', 'price', 'on', 'his', 'head', 'Daily', 'Pilot', 'Multimilionaire', 'Samuel', 'Popeil', 'Craftfest', 'A', 'hobby', 'for', 'some', 'for', 'others', 'a', 'fulltime', 'gig', 'of', 'the', 'pieces', 'hes', 'made', 'in', 'those', 'four', 'ye', 'Young', 'inventors', 'show', 'creativity', 'By', 'MEGAN', 'HUSSEY', 'HOLIDAY', 'A', 'cutting', 'board', 'for', 'the', 'blind', 'A', 'GPS', 'golf', 'ball', 'An', 'a', 'The', 'wine', 'revolution', 'Inventors', 'simple', 'machine', 'could', 'radically', 'change', 'wine', 'service', 'by', 'Timothy', 'J', 'Carroll', 'Ha', 'Syracuse', 'Peace', 'Councils', 'Plowshares', 'Craft', 'fair', 'and', 'Winter', 'Peace', 'Festival', 'So', 'next', 'holiday', 'season', 'she', 'ma', 'Inventors', 'Terminal', 'Cancer', 'Courtesy', 'Of', 'Verichip', 'Disinformation', 'Inventors', 'Terminal', 'Cancer', 'Courtesy', 'Inventors', 'terminal', 'cancer', 'courtesy', 'of', 'Verichip', 'Give', 'it', 'to', 'me', 'Raw', 'Inventors', 'terminal', 'cancer', 'courte', 'Holiday', 'Arts', 'and', 'Crafts', 'Show', 'at', 'the', 'Butler', 'The', 'th', 'Annual', 'American', 'Holiday', 'Fine', 'Arts', 'and', 'Crafts', 'Show', 'kicked', 'o', 'On', 'Gay', 'Marriage', 'and', 'Other', 'Inventions', 'of', 'ImPerfect', 'Design', 'On', 'Gay', 'Marriage', 'and', 'Other', 'Inventions', 'of', 'Im', 'Generational', 'Equity', 'Generational', 'Equity', 'Fast', 'Company', 'your', 'invention', 'but', 'because', 'if', 'they', 'sign', 'they', 'are', 'crea', 'Societys', 'show', 'dispays', 'variety', 'of', 'arts', 'and', 'crafts', 'in', 'the', 'background', 'residents', 'perused', 'dozens', 'of', 'booth', 'Your', 'friends', 'email', 'Is', 'is', 'nice', 'to', 'know', 'the', 'world', 'still', 'has', 'inventors', 'and', 'thinkers', 'in', 'it', 'WOW', 'It', 'is', 'ab', 'NewProductHelpcom', 'Tabbed', 'as', 'Official', 'Marketing', 'Representative', 'of', 'Inventors', 'Club', 'News', 'Inventions', 'Patent', 'Holiday', 'craft', 'show', 'attracts', 'hundreds', 'Give', 'me', 'a', 'craft', 'show', 'any', 'day', 'Hanley', 'said', 'The', 'items', 'are', 'oneofakind', 'Kodak', 'leaving', 'a', 'field', 'it', 'pioneered', 'Longtime', 'Kodak', 'researcher', 'Chang', 'Ting', 'an', 'engineering', 'professor', 'at', 'the', 'Unive', 'A', 'region', 'of', 'inventions', 'RT', 'In', 'addition', 'to', 'a', 'great', 'historical', 'and', 'cultural', 'heritage', 'the', 'Nizhny', 'Novgorod', 'Marketing', 'the', 'biggest', 'hurdle', 'for', 'game', 'inventors', 'Business', 'Exchange', 'To', 'hear', 'him', 'tell', 'it', 'Evan', 'Koch', 'is', 'sitting', 'The', 'ReInventors', 'The', 'ReInventors', 'General', 'Discussion', 'discussion', 'New', 'Inductees', 'To', 'Inventors', 'Hall', 'Of', 'Fame', 'On', 'Gay', 'Marriage', 'and', 'Other', 'Inventions', 'of', 'ImPerfect', 'Design', 'They', 'drop', 'quarters', 'in', 'parking', 'meters', 'go']\n"
     ]
    }
   ],
   "source": [
    "print(data[:900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa9aa037-f34f-425e-8bcf-c1cc484b9e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coope\\miniforge3\\envs\\homl3\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 13 variables whereas the saved optimizer has 24 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "#model = load_model(\"troll_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911137dd",
   "metadata": {},
   "source": [
    "#### LSTM model and train test preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1babd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=84294, oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(data) #it's going to fit on the data in the forms of lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de90b86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text=tokenizer.texts_to_sequences(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63af34c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33262d23",
   "metadata": {},
   "source": [
    "### Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c32ae96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list=[]\n",
    "for i in encoded_text:\n",
    "    if len(i)>1:\n",
    "        for j in range(2,len(i)+1):\n",
    "            data_list.append(i[:j])\n",
    "#             print(i[:j]) # if you want to check data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f592d01d",
   "metadata": {},
   "source": [
    "#### Paddding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "905f8572",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=25\n",
    "#max length of line is 25 token per line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a7c4079",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences=pad_sequences(data_list,maxlen=max_length,padding=\"pre\") # we set the lenght size equal to max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f1a3a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=sequences[:,:-1]\n",
    "y=sequences[:,-1].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c56f1861-0cea-404e-999f-441c04d716fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30735, 24), (30735,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd466740",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length=X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e6e819",
   "metadata": {},
   "source": [
    "#### Build Model\n",
    "- We will build a simple LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7291423-1dc5-4c8c-b967-5e18138a51c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size,50)) \n",
    "#The first layer is the Embedded layer that uses 50-length vectors\n",
    "#return_sequences=True because we add another LSTM\n",
    "model.add(LSTM(100,return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100,activation=\"relu\"))\n",
    "model.add(Dense(vocab_size,activation=\"softmax\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5665f431-1b98-4352-ae71-317090aef27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape=(None, seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d6f5963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)             </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">   Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2,649,450</span> │\n",
       "├──────────────────────────┼───────────────────┼───────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">60,400</span> │\n",
       "├──────────────────────────┼───────────────────┼───────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │\n",
       "├──────────────────────────┼───────────────────┼───────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├──────────────────────────┼───────────────────┼───────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52989</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">5,351,889</span> │\n",
       "└──────────────────────────┴───────────────────┴───────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m50\u001b[0m)    │ \u001b[38;5;34m2,649,450\u001b[0m │\n",
       "├──────────────────────────┼───────────────────┼───────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m100\u001b[0m)   │    \u001b[38;5;34m60,400\u001b[0m │\n",
       "├──────────────────────────┼───────────────────┼───────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │    \u001b[38;5;34m80,400\u001b[0m │\n",
       "├──────────────────────────┼───────────────────┼───────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │    \u001b[38;5;34m10,100\u001b[0m │\n",
       "├──────────────────────────┼───────────────────┼───────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52989\u001b[0m)     │ \u001b[38;5;34m5,351,889\u001b[0m │\n",
       "└──────────────────────────┴───────────────────┴───────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,152,239</span> (31.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,152,239\u001b[0m (31.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,152,239</span> (31.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,152,239\u001b[0m (31.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62c42ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f06cbeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 31ms/step - accuracy: 0.0320 - loss: 7.5488\n",
      "Epoch 2/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 31ms/step - accuracy: 0.0389 - loss: 7.2329\n",
      "Epoch 3/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.0467 - loss: 6.9745\n",
      "Epoch 4/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 37ms/step - accuracy: 0.0487 - loss: 6.7755\n",
      "Epoch 5/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.0527 - loss: 6.6142\n",
      "Epoch 6/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 39ms/step - accuracy: 0.0580 - loss: 6.4400\n",
      "Epoch 7/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 32ms/step - accuracy: 0.0623 - loss: 6.2310\n",
      "Epoch 8/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.0712 - loss: 6.0164\n",
      "Epoch 9/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.0784 - loss: 5.8190\n",
      "Epoch 10/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 34ms/step - accuracy: 0.0851 - loss: 5.6291\n",
      "Epoch 11/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 40ms/step - accuracy: 0.0927 - loss: 5.4461\n",
      "Epoch 12/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 33ms/step - accuracy: 0.0956 - loss: 5.2657\n",
      "Epoch 13/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.1041 - loss: 5.0879\n",
      "Epoch 14/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.1092 - loss: 4.9276\n",
      "Epoch 15/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 37ms/step - accuracy: 0.1142 - loss: 4.7843\n",
      "Epoch 16/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 38ms/step - accuracy: 0.1213 - loss: 4.6429\n",
      "Epoch 17/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 33ms/step - accuracy: 0.1293 - loss: 4.5179\n",
      "Epoch 18/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 39ms/step - accuracy: 0.1384 - loss: 4.3993\n",
      "Epoch 19/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.1474 - loss: 4.2965\n",
      "Epoch 20/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.1590 - loss: 4.1985\n",
      "Epoch 21/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 37ms/step - accuracy: 0.1695 - loss: 4.1047\n",
      "Epoch 22/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.1770 - loss: 4.0183\n",
      "Epoch 23/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 40ms/step - accuracy: 0.1905 - loss: 3.9375\n",
      "Epoch 24/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 33ms/step - accuracy: 0.1986 - loss: 3.8621\n",
      "Epoch 25/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 40ms/step - accuracy: 0.2077 - loss: 3.7809\n",
      "Epoch 26/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 34ms/step - accuracy: 0.2185 - loss: 3.7145\n",
      "Epoch 27/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 39ms/step - accuracy: 0.2281 - loss: 3.6401\n",
      "Epoch 28/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 36ms/step - accuracy: 0.2382 - loss: 3.5756\n",
      "Epoch 29/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 33ms/step - accuracy: 0.2500 - loss: 3.5061\n",
      "Epoch 30/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 43ms/step - accuracy: 0.2575 - loss: 3.4449\n",
      "Epoch 31/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.2684 - loss: 3.3846\n",
      "Epoch 32/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 38ms/step - accuracy: 0.2784 - loss: 3.3271\n",
      "Epoch 33/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 37ms/step - accuracy: 0.2868 - loss: 3.2652\n",
      "Epoch 34/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 34ms/step - accuracy: 0.2952 - loss: 3.2118\n",
      "Epoch 35/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 40ms/step - accuracy: 0.3052 - loss: 3.1603\n",
      "Epoch 36/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 34ms/step - accuracy: 0.3140 - loss: 3.1003\n",
      "Epoch 37/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 40ms/step - accuracy: 0.3235 - loss: 3.0520\n",
      "Epoch 38/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.3335 - loss: 3.0014\n",
      "Epoch 39/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.3421 - loss: 2.9546\n",
      "Epoch 40/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 38ms/step - accuracy: 0.3478 - loss: 2.9041\n",
      "Epoch 41/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.3565 - loss: 2.8658\n",
      "Epoch 42/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.3677 - loss: 2.8133\n",
      "Epoch 43/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 37ms/step - accuracy: 0.3771 - loss: 2.7687\n",
      "Epoch 44/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.3828 - loss: 2.7332\n",
      "Epoch 45/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 40ms/step - accuracy: 0.3910 - loss: 2.6865\n",
      "Epoch 46/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.4021 - loss: 2.6380\n",
      "Epoch 47/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 41ms/step - accuracy: 0.4068 - loss: 2.6068\n",
      "Epoch 48/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 34ms/step - accuracy: 0.4146 - loss: 2.5710\n",
      "Epoch 49/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 41ms/step - accuracy: 0.4184 - loss: 2.5376\n",
      "Epoch 50/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.4302 - loss: 2.4956\n",
      "Epoch 51/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 40ms/step - accuracy: 0.4353 - loss: 2.4561\n",
      "Epoch 52/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.4437 - loss: 2.4161\n",
      "Epoch 53/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.4512 - loss: 2.3823\n",
      "Epoch 54/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 38ms/step - accuracy: 0.4566 - loss: 2.3632\n",
      "Epoch 55/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.4656 - loss: 2.3133\n",
      "Epoch 56/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.4729 - loss: 2.2810\n",
      "Epoch 57/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 39ms/step - accuracy: 0.4785 - loss: 2.2463\n",
      "Epoch 58/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.4885 - loss: 2.2055\n",
      "Epoch 59/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.4914 - loss: 2.1786\n",
      "Epoch 60/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.5015 - loss: 2.1441\n",
      "Epoch 61/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.5058 - loss: 2.1107\n",
      "Epoch 62/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.5116 - loss: 2.0794\n",
      "Epoch 63/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 37ms/step - accuracy: 0.5197 - loss: 2.0501\n",
      "Epoch 64/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.3211 - loss: 4.0443\n",
      "Epoch 65/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.1005 - loss: 5.1344\n",
      "Epoch 66/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.1550 - loss: 4.2700\n",
      "Epoch 67/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.2041 - loss: 3.8252\n",
      "Epoch 68/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 41ms/step - accuracy: 0.2501 - loss: 3.5191\n",
      "Epoch 69/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.2843 - loss: 3.2873\n",
      "Epoch 70/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 41ms/step - accuracy: 0.3178 - loss: 3.0976\n",
      "Epoch 71/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.3430 - loss: 2.9469\n",
      "Epoch 72/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 41ms/step - accuracy: 0.3699 - loss: 2.8121\n",
      "Epoch 73/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.3923 - loss: 2.6963\n",
      "Epoch 74/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 39ms/step - accuracy: 0.4136 - loss: 2.5851\n",
      "Epoch 75/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.4321 - loss: 2.4880\n",
      "Epoch 76/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.4513 - loss: 2.3977\n",
      "Epoch 77/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 40ms/step - accuracy: 0.4643 - loss: 2.3179\n",
      "Epoch 78/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.4857 - loss: 2.2282\n",
      "Epoch 79/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.4984 - loss: 2.1607\n",
      "Epoch 80/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.5122 - loss: 2.0840\n",
      "Epoch 81/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 41ms/step - accuracy: 0.5287 - loss: 2.0053\n",
      "Epoch 82/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.5455 - loss: 1.9277\n",
      "Epoch 83/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 42ms/step - accuracy: 0.5571 - loss: 1.8677\n",
      "Epoch 84/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.5704 - loss: 1.8067\n",
      "Epoch 85/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 41ms/step - accuracy: 0.5830 - loss: 1.7399\n",
      "Epoch 86/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.5961 - loss: 1.6814\n",
      "Epoch 87/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 41ms/step - accuracy: 0.6071 - loss: 1.6255\n",
      "Epoch 88/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.6223 - loss: 1.5605\n",
      "Epoch 89/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 40ms/step - accuracy: 0.6338 - loss: 1.5037\n",
      "Epoch 90/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.6465 - loss: 1.4562\n",
      "Epoch 91/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 39ms/step - accuracy: 0.6562 - loss: 1.4132\n",
      "Epoch 92/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 37ms/step - accuracy: 0.6691 - loss: 1.3563\n",
      "Epoch 93/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.6789 - loss: 1.3100\n",
      "Epoch 94/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.6875 - loss: 1.2663\n",
      "Epoch 95/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.6976 - loss: 1.2244\n",
      "Epoch 96/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 41ms/step - accuracy: 0.7087 - loss: 1.1799\n",
      "Epoch 97/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.7183 - loss: 1.1376\n",
      "Epoch 98/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 41ms/step - accuracy: 0.7279 - loss: 1.0955\n",
      "Epoch 99/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.7376 - loss: 1.0584\n",
      "Epoch 100/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 41ms/step - accuracy: 0.7457 - loss: 1.0275\n",
      "Epoch 101/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.7487 - loss: 0.9987\n",
      "Epoch 102/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 40ms/step - accuracy: 0.7596 - loss: 0.9630\n",
      "Epoch 103/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 36ms/step - accuracy: 0.7644 - loss: 0.9334\n",
      "Epoch 104/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.7694 - loss: 0.9101\n",
      "Epoch 105/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 39ms/step - accuracy: 0.7834 - loss: 0.8670\n",
      "Epoch 106/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.7908 - loss: 0.8335\n",
      "Epoch 107/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 39ms/step - accuracy: 0.7910 - loss: 0.8254\n",
      "Epoch 108/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.7982 - loss: 0.7975\n",
      "Epoch 109/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 40ms/step - accuracy: 0.8049 - loss: 0.7708\n",
      "Epoch 110/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 39ms/step - accuracy: 0.8094 - loss: 0.7489\n",
      "Epoch 111/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 38ms/step - accuracy: 0.8166 - loss: 0.7241\n",
      "Epoch 112/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.8177 - loss: 0.7173\n",
      "Epoch 113/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 42ms/step - accuracy: 0.8266 - loss: 0.6825\n",
      "Epoch 114/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.8308 - loss: 0.6643\n",
      "Epoch 115/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 41ms/step - accuracy: 0.8333 - loss: 0.6549\n",
      "Epoch 116/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 36ms/step - accuracy: 0.8380 - loss: 0.6273\n",
      "Epoch 117/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 40ms/step - accuracy: 0.8449 - loss: 0.6066\n",
      "Epoch 118/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 39ms/step - accuracy: 0.8458 - loss: 0.5970\n",
      "Epoch 119/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.8442 - loss: 0.6049\n",
      "Epoch 120/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.8532 - loss: 0.5718\n",
      "Epoch 121/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.8592 - loss: 0.5527\n",
      "Epoch 122/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.8586 - loss: 0.5516\n",
      "Epoch 123/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.8604 - loss: 0.5401\n",
      "Epoch 124/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.8643 - loss: 0.5210\n",
      "Epoch 125/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8679 - loss: 0.5100\n",
      "Epoch 126/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 40ms/step - accuracy: 0.8653 - loss: 0.5150\n",
      "Epoch 127/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8691 - loss: 0.5005\n",
      "Epoch 128/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.8750 - loss: 0.4783\n",
      "Epoch 129/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.8743 - loss: 0.4781\n",
      "Epoch 130/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 37ms/step - accuracy: 0.8795 - loss: 0.4588\n",
      "Epoch 131/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 41ms/step - accuracy: 0.8738 - loss: 0.4729\n",
      "Epoch 132/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8779 - loss: 0.4564\n",
      "Epoch 133/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 38ms/step - accuracy: 0.8809 - loss: 0.4461\n",
      "Epoch 134/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8792 - loss: 0.4456\n",
      "Epoch 135/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8823 - loss: 0.4355\n",
      "Epoch 136/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8832 - loss: 0.4279\n",
      "Epoch 137/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.8860 - loss: 0.4203\n",
      "Epoch 138/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 41ms/step - accuracy: 0.8851 - loss: 0.4231\n",
      "Epoch 139/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8889 - loss: 0.4125\n",
      "Epoch 140/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8909 - loss: 0.4031\n",
      "Epoch 141/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8890 - loss: 0.4072\n",
      "Epoch 142/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8865 - loss: 0.4084\n",
      "Epoch 143/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8930 - loss: 0.3907\n",
      "Epoch 144/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8929 - loss: 0.3928\n",
      "Epoch 145/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8981 - loss: 0.3769\n",
      "Epoch 146/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8943 - loss: 0.3840\n",
      "Epoch 147/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 39ms/step - accuracy: 0.8934 - loss: 0.3858\n",
      "Epoch 148/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8904 - loss: 0.3907\n",
      "Epoch 149/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8984 - loss: 0.3648\n",
      "Epoch 150/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8956 - loss: 0.3758\n",
      "Epoch 151/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 39ms/step - accuracy: 0.8943 - loss: 0.3745\n",
      "Epoch 152/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 39ms/step - accuracy: 0.9009 - loss: 0.3556\n",
      "Epoch 153/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8979 - loss: 0.3605\n",
      "Epoch 154/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 38ms/step - accuracy: 0.8936 - loss: 0.3742\n",
      "Epoch 155/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 41ms/step - accuracy: 0.8961 - loss: 0.3623\n",
      "Epoch 156/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 40ms/step - accuracy: 0.9004 - loss: 0.3514\n",
      "Epoch 157/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 40ms/step - accuracy: 0.8978 - loss: 0.3530\n",
      "Epoch 158/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 39ms/step - accuracy: 0.9015 - loss: 0.3409\n",
      "Epoch 159/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 39ms/step - accuracy: 0.9015 - loss: 0.3419\n",
      "Epoch 160/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 41ms/step - accuracy: 0.8916 - loss: 0.3730\n",
      "Epoch 161/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.9006 - loss: 0.3462\n",
      "Epoch 162/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 44ms/step - accuracy: 0.9035 - loss: 0.3316\n",
      "Epoch 163/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 41ms/step - accuracy: 0.9067 - loss: 0.3247\n",
      "Epoch 164/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 39ms/step - accuracy: 0.9005 - loss: 0.3448\n",
      "Epoch 165/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.8980 - loss: 0.3480\n",
      "Epoch 166/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 41ms/step - accuracy: 0.9027 - loss: 0.3333\n",
      "Epoch 167/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 40ms/step - accuracy: 0.9012 - loss: 0.3367\n",
      "Epoch 168/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.9056 - loss: 0.3238\n",
      "Epoch 169/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.9025 - loss: 0.3339\n",
      "Epoch 170/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 41ms/step - accuracy: 0.8976 - loss: 0.3473\n",
      "Epoch 171/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 44ms/step - accuracy: 0.9028 - loss: 0.3299\n",
      "Epoch 172/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 42ms/step - accuracy: 0.9026 - loss: 0.3286\n",
      "Epoch 173/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 41ms/step - accuracy: 0.9036 - loss: 0.3250\n",
      "Epoch 174/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 40ms/step - accuracy: 0.9010 - loss: 0.3337\n",
      "Epoch 175/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 41ms/step - accuracy: 0.9043 - loss: 0.3209\n",
      "Epoch 176/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 42ms/step - accuracy: 0.9040 - loss: 0.3266\n",
      "Epoch 177/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 44ms/step - accuracy: 0.9032 - loss: 0.3247\n",
      "Epoch 178/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 43ms/step - accuracy: 0.9051 - loss: 0.3169\n",
      "Epoch 179/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 41ms/step - accuracy: 0.9000 - loss: 0.3324\n",
      "Epoch 180/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 42ms/step - accuracy: 0.9020 - loss: 0.3261\n",
      "Epoch 181/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 41ms/step - accuracy: 0.9039 - loss: 0.3164\n",
      "Epoch 182/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 44ms/step - accuracy: 0.9030 - loss: 0.3204\n",
      "Epoch 183/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 33ms/step - accuracy: 0.9041 - loss: 0.3178\n",
      "Epoch 184/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 45ms/step - accuracy: 0.9063 - loss: 0.3083\n",
      "Epoch 185/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.9039 - loss: 0.3151\n",
      "Epoch 186/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 44ms/step - accuracy: 0.8997 - loss: 0.3319\n",
      "Epoch 187/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 34ms/step - accuracy: 0.9023 - loss: 0.3225\n",
      "Epoch 188/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 47ms/step - accuracy: 0.9025 - loss: 0.3203\n",
      "Epoch 189/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 44ms/step - accuracy: 0.9059 - loss: 0.3137\n",
      "Epoch 190/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 34ms/step - accuracy: 0.9043 - loss: 0.3126\n",
      "Epoch 191/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 46ms/step - accuracy: 0.9087 - loss: 0.2988\n",
      "Epoch 192/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 42ms/step - accuracy: 0.9030 - loss: 0.3176\n",
      "Epoch 193/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 45ms/step - accuracy: 0.9025 - loss: 0.3175\n",
      "Epoch 194/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 43ms/step - accuracy: 0.9050 - loss: 0.3074\n",
      "Epoch 195/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 44ms/step - accuracy: 0.9090 - loss: 0.2995\n",
      "Epoch 196/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 45ms/step - accuracy: 0.9050 - loss: 0.3127\n",
      "Epoch 197/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 45ms/step - accuracy: 0.9018 - loss: 0.3205\n",
      "Epoch 198/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 43ms/step - accuracy: 0.9071 - loss: 0.3013\n",
      "Epoch 199/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 44ms/step - accuracy: 0.9076 - loss: 0.3020\n",
      "Epoch 200/200\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 43ms/step - accuracy: 0.9058 - loss: 0.3044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x243c60502e0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,batch_size=32,epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e41f61",
   "metadata": {},
   "source": [
    "### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56f2d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length = 15\n",
    "\n",
    "def generate_text(input_text, no_lines):\n",
    "    general_text = []\n",
    "    original_input = input_text  # keep the original prefix\n",
    "\n",
    "    for i in range(no_lines):\n",
    "        text = []\n",
    "        for _ in range(text_length):\n",
    "            encoded = tokenizer.texts_to_sequences([input_text])\n",
    "            encoded = pad_sequences(encoded, maxlen=seq_length, padding=\"pre\")\n",
    "            y_pred = np.argmax(model.predict(encoded), axis=-1)\n",
    "\n",
    "            predicted_word = \"\"\n",
    "            for word, index in tokenizer.word_index.items():\n",
    "                if index == y_pred:\n",
    "                    predicted_word = word\n",
    "                    break\n",
    "\n",
    "            input_text = input_text + ' ' + predicted_word\n",
    "            text.append(predicted_word)\n",
    "\n",
    "        line = original_input + \" \" + \" \".join(text)\n",
    "        general_text.append(line)\n",
    "\n",
    "        input_text = text[-1]\n",
    "\n",
    "    return general_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0764b35d-2337-4769-a843-e401bf2a1891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['There are million ants for every person in the world is a street smh people need to',\n",
       " 'There are overcome fear act as if it wer impossible to fail and it shall be easy',\n",
       " 'There are button as gould raises the most spirit in life is a minute or am slowly']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text=\"There are\"\n",
    "text_produced=generate_text(input_text,3)\n",
    "text_produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f106f045-5129-4fdf-a508-20c5c6751f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['How do i check my stats for fantasy football i forget the website hhahahahahaha man no happy',\n",
       " 'How do thanksgiving donniewahlberg i hope your results with legs to see his realskipbayless colts to stay',\n",
       " 'How do with alzheimers retirement revolution the new reality the twins weekly reunion nothing only drink credible']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text=\"How do\"\n",
    "text_produced=generate_text(input_text,3)\n",
    "text_produced"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
